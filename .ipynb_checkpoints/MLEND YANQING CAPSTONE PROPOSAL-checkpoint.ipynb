{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Engineer ND Capstone Proposal "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Yanqing Zhu\n",
    "> May 31st 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Domain Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bay area is a expensive place to live, especially for housing, purchasing or selling a home is no small deal, the correct buy/sell action at the right time, might be more profitable than working for 20 years. I'm hoping to predict the actual home sale price with all housing related feature plus tech sector stock price for bayarea's house price.\n",
    "\n",
    "This type of problem is normally solved using regression models (with variance, linear/polynormial etc).\n",
    "From [Multivariant models](http://iopscience.iop.org/article/10.1088/1757-899X/263/4/042098/pdf) and [Results from some commmon machine learning models](https://web.stanford.edu/class/cs221/2017/restricted/p-final/ianjones/final.pdf), we have more insights on the common approachs to solve this problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. This is a regression problem (continuous results)\n",
    "2. Input of the model will be each house's property value (size, utility, location), transction details (selling price, transaction time) and stock market price (pre-selected companies)\n",
    "3. Output of the model should be a number in dollars predicting the current selling price.\n",
    "1. You are provided with a full list of real estate properties in three counties (Los Angeles, Orange and Ventura, California) data in 2016.\n",
    "2. The train data has all the transactions before October 15, 2016, plus some of the transactions after October 15, 2016.\n",
    "3. The test data in the public leaderboard has the rest of the transactions between October 15 and December 31, 2016.\n",
    "The rest of the test data, which is used for calculating the private leaderboard, is all the properties in October 15, 2017, to December 15, 2017. This period is called the \"sales tracking period\", during which we will not be taking any submissions.\n",
    "4. You are asked to predict 6 time points for all properties: October 2016 (201610), November 2016 (201611), December 2016 (201612), October 2017 (201710), November 2017 (201711), and December 2017 (201712).\n",
    "5. Not all the properties are sold in each time period. If a property was not sold in a certain time period, that particular row will be ignored when calculating your score.\n",
    "6. If a property is sold multiple times within 31 days, we take the first reasonable value as the ground truth. By \"reasonable\", we mean if the data seems wrong, we will take the transaction that has a value that makes more sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets and Inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data will come from [https://www.kaggle.com/c/zillow-prize-1/data]\n",
    "\n",
    "1. properties_2016.csv - all the properties with their home features for 2016. Note: Some 2017 new properties don't have any data yet except for their parcelid's. Those data points should be populated when properties_2017.csv is available.\n",
    "2. properties_2017.csv - all the properties with their home features for 2017 (released on 10/2/2017)\n",
    "3. train_2016.csv - the training set with transactions from 1/1/2016 to 12/31/2016\n",
    "4. train_2017.csv - the training set with transactions from 1/1/2017 to 9/15/2017 (released on 10/2/2017)\n",
    "6. All features\n",
    "\n",
    "  * 'airconditioningtypeid'\n",
    "  * 'architecturalstyletypeid'\n",
    "  * 'basementsqft'\n",
    "  * 'bathroomcnt'\n",
    "  * 'bedroomcnt'\n",
    "  * 'buildingqualitytypeid'\n",
    "  * 'buildingclasstypeid'\n",
    "  * 'calculatedbathnbr'\n",
    "  * decktypeid'\n",
    "  * threequarterbathnbr'\n",
    "  * finishedfloor1squarefeet'\n",
    "  * calculatedfinishedsquarefeet'\n",
    "  * finishedsquarefeet6'\n",
    "  * finishedsquarefeet12'\n",
    "  * finishedsquarefeet13'\n",
    "  * finishedsquarefeet15'\n",
    "  * finishedsquarefeet50'\n",
    "  * fips'\n",
    "  * fireplacecnt'\n",
    "  * fireplaceflag'\n",
    "  * fullbathcnt'\n",
    "  * garagecarcnt'\n",
    "  * garagetotalsqft'\n",
    "  * hashottuborspa'\n",
    "  * heatingorsystemtypeid'\n",
    "  * latitude'\n",
    "  * longitude'\n",
    "  * lotsizesquarefeet'\n",
    "  * numberofstories'\n",
    "  * parcelid'\n",
    "  * poolcnt'\n",
    "  * poolsizesum'\n",
    "  * pooltypeid10'\n",
    "  * pooltypeid2'\n",
    "  * pooltypeid7'\n",
    "  * propertycountylandusecode'\n",
    "  * propertylandusetypeid'\n",
    "  * propertyzoningdesc'\n",
    "  * rawcensustractandblock'\n",
    "  * censustractandblock'\n",
    "  * regionidcounty'\n",
    "  * regionidcity'\n",
    "  * regionidzip'\n",
    "  * regionidneighborhood'\n",
    "  * roomcnt'\n",
    "  * storytypeid'\n",
    "  * typeconstructiontypeid'\n",
    "  * unitcnt'\n",
    "  * yardbuildingsqft17'\n",
    "  * yardbuildingsqft26'\n",
    "  * 'yearbuilt'\n",
    "  * 'taxvaluedollarcnt'\n",
    "  * 'structuretaxvaluedollarcnt'\n",
    "  * 'landtaxvaluedollarcnt'\n",
    "  * 'taxamount'\n",
    "  * 'assessmentyear'\n",
    "  * 'taxdelinquencyflag'\n",
    "  * 'taxdelinquencyyear'\n",
    "  \n",
    "7. each train.csv data is in shape (90275, 3)\n",
    "8. each property.csv is in shape (2985217, 58)  \n",
    "9. Stock info will be gathered from https://finance.yahoo.com/quote/MSFT?p=MSFT on a daily bases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mutiple regression model (CNN, Linear model, K-means, polynomial model) with PCA will be experimented using keras/scikit, the baseline comparsion model will be a simple naive Linear model, for stock info, there will be 2 options to test, 1st, treated it as an addtional feature that each transaction shares based on its date. the 2nd option will be adding another hyper param to give that stock info different weight. it does not change the output of this model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "primay benchmark model will be naive bayes from sckit\n",
    "\n",
    "if beat by far, will use [leader board model (global score)](https://www.kaggle.com/c/zillow-prize-1/leaderboard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean Absolute Error between the predicted log error and the actual log error. The log error is defined as\n",
    "logerror=log(Zestimate)âˆ’log(SalePrice)\n",
    "and it is recorded in the transactions training data. If a transaction didn't happen for a property during that period of time, that row is ignored and not counted in the calculation of MAE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the info above, we can inferred that a regression model would be best to fit this question, with additional tech sector stock market as an additional feature (weighted or not), we will start with some standardlization and feature extraction PCA, after that will be training using different model as stated in solution statement and compare their results, based on suggestion from reviewer, Xgboost or LightGBM will also be added in at the end to further improve result. if those customized model does not perform well, we probably will start with half trainied gold model from kaggle then move forward to retrain specifically for Bay area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
